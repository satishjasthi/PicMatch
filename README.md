---
title: 'PicMatch: Your Visual Search Companion'
emoji: ğŸ“·ğŸ”
colorFrom: blue
colorTo: green
sdk: gradio
python_version: 3.9
sdk_version: 4.39.0
suggested_hardware: t4-small
suggested_storage: medium
app_file: app.py
fullWidth: true
header: mini
short_description: Search images using text or other images as queries.
models:
- wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M
- Salesforce/blip-image-captioning-base


tags:
- image search
- visual search
- image processing
- CLIP
- image captioning
thumbnail: https://example.com/thumbnail.png
pinned: true
hf_oauth: false
disable_embedding: false
startup_duration_timeout: 30m
custom_headers:
  cross-origin-embedder-policy: require-corp
  cross-origin-opener-policy: same-origin
  cross-origin-resource-policy: cross-origin

---

# ğŸ“¸ PicMatch: Your Visual Search Companion ğŸ”

PicMatch lets you effortlessly search through your image archive using either a text description or another image as your query.  Find those needle-in-a-haystack photos in a flash! âœ¨

Try PicMatch image search with 25,000 Unsplash images on this [ğŸ¤— Space](https://huggingface.co/spaces/satishjasthij/PicMatch)

## ğŸš€ Getting Started:

1. **Prerequisites:** Ensure you have Python 3.9 or higher installed on your system. ğŸ

2. **Create a Virtual Environment:**
   ```bash
   python -m venv env
   ```

3. **Activate the Environment:**
   ```bash
   source ./venv/bin/activate 
   ```

4. **Install Dependencies:**
   ```bash
   python -m pip install -r requirements.txt
   ```

5. **Start the App (with Sample Data):**
   ```bash
   python app.py
   ```

6. **Open Your Browser:**  Head to `localhost:7860` to access the PicMatch interface. ğŸŒ

## ğŸ“‚ Data: Organize Your Visual Treasures 

Make sure you have the following folders in your project's root directory:

```
data
â”œâ”€â”€ images   
â””â”€â”€ features
```

## ğŸ› ï¸ Image Pipeline: Download & Process with Speed âš¡

The `engine/download_data.py` Python script streamlines downloading and processing images from a list of URLs. It's designed for performance and reliability:

- **Async Operations:**  Uses `asyncio` for concurrent image downloading and processing. â©
- **Rate Limiting:**  Follows API usage rules to prevent blocks with a `RateLimiter`. ğŸš¦
- **Parallel Resizing:**  Employs a `ProcessPoolExecutor` for fast image resizing. âš™ï¸
- **State Management:**  Saves progress in a JSON file so you can resume later. ğŸ’¾

### ğŸ—ï¸ Key Components:

- **`ImagePipeline` Class:** Manages the entire pipeline, its state, and rate limiting. ğŸ›ï¸
- **Functions:** Handle URL feeding (`url_feeder`), downloading (`image_downloader`), and processing (`image_processor`). ğŸ“¥
- **`ImageSaver` Class:** Defines how images are processed and saved. ğŸ–¼ï¸
- **`resize_image` Function:**  Ensures image resizing maintains the correct aspect ratio. ğŸ“

### ğŸƒ How it Works:

1. **Start:** Configure the pipeline with your URL list, download limits, and rate settings. 
2. **Feed URLs:** Asynchronously read URLs from your file. 
3. **Download:** Download images concurrently while respecting rate limits. 
4. **Process:** Save the original images and resize them in parallel. 
5. **Save State:**  Regularly save progress to avoid starting over if interrupted. 

To get the sample data run the command
```bash
cd engine && python download_data.py
```

## âœ¨ Feature Creation: Making Your Images Searchable âœ¨

This step prepares your images for searching.  We generate two types of embeddings:

- **Visual Embeddings (CLIP):** Capture the visual content of your images. ğŸ‘ï¸â€ğŸ—¨ï¸ 
- **Textual Embeddings:** Create embeddings from image captions for text-based search. ğŸ’¬

To generate these features run the command 
```bash
cd engine && python generate_features.py
```
This process uses these awesome models from Hugging Face:

- TinyCLIP: `wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M` 
- BLIP Image Captioning: `Salesforce/blip-image-captioning-base`
- SentenceTransformer: `all-MiniLM-L6-v2` 

## âš¡ Asynchronous Feature Extraction: Supercharge Your Process âš¡

This script extracts image features (both visual and textual) efficiently:

- **Asynchronous:**  Loads images, extracts features, and saves them concurrently. âš¡
- **Dual Embeddings:** Creates both CLIP (visual) and caption (textual) embeddings. ğŸ–¼ï¸ğŸ“
- **Checkpoints:** Keeps track of progress and allows resuming from interruptions. ğŸ”„
- **Parallel:** Uses multiple CPU cores for feature extraction. âš™ï¸


## ğŸ“Š Vector Database Module: Milvus for Fast Search ğŸš¤

This module connects to the Milvus vector database to store and search your image embeddings:

- **Milvus:**  A high-performance database built for handling vector data. ğŸ“Š
- **Easy Interface:**  Provides a simple way to manage embeddings and perform searches. ğŸ”
- **Single Server:**  Ensures only one Milvus server is running for efficiency. 
- **Indexing:** Automatically creates an index to speed up your searches. ğŸš€
- **Similarity Search:** Find the most similar images using cosine similarity. ğŸ’¯



## ğŸ“š References: The Brains Behind PicMatch ğŸ§ 

PicMatch leverages these incredible open-source projects:

- **TinyCLIP:**  The visual powerhouse for understanding your images.  
  - ğŸ‘‰ [https://huggingface.co/wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M](https://huggingface.co/wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M)

- **Image Captioning:** The wordsmith that describes your photos in detail. 
  - ğŸ‘‰ [https://huggingface.co/Salesforce/blip-image-captioning-base](https://huggingface.co/Salesforce/blip-image-captioning-base)

- **Sentence Transformers:** Turns captions into embeddings for text-based search. 
  - ğŸ‘‰ [https://sbert.net](https://sbert.net)

- **Unsplash:** Images used were taken from Unsplash's open source data
   - ğŸ‘‰ [https://github.com/unsplash/datasets](https://github.com/unsplash/datasets)

Let's give credit where credit is due! ğŸ™Œ These projects make PicMatch smarter and more capable. 
